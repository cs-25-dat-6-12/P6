import time
import openai
import json
import pandas as pd
from datetime import datetime

# template
# {"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-3.5-turbo-0125", "messages": [{"role": "system", "content": "You are a helpful assistant."},{"role": "user", "content": "Hello world!"}],"max_tokens": 1000}}


def update_history(string):
    with open(r"app\openAiBatchHistory.txt", "a") as history:
        history.write(f"{datetime.now()}\t\t" + string + "\n\n")


def create_name_list(block, blocks_df):
    # given a set of record indexes, fetch each name from their dataframe and write a string where each name is on a new line
    name_list = ""
    for index in block:
        name_list += blocks_df.iloc[index]["title"] + "\n"
    name_list = name_list[:-1]
    return name_list


def prepare_batch_file(
    blocks,
    df,
    blocks_df,
    filepath,
    model="gpt-4.1-nano",
    max_tokens_per_request=5000,
):
    # given a blocks-dictionary as generated by textBlocking.py, the dataset the blocks were made for "df",
    # and the dataset used to create those blocks "blocks_df", write a file with gpt-4.1-nano requests for batch processing
    print(f"Overwriting {filepath}")

    for i in range(10):
        print(f"You have {10-i} seconds to cancel! ", end="\r")
        time.sleep(1)

    with open(filepath, "w", encoding="utf-8") as file:
        for record in blocks:
            print(
                f"Writing request for block {record}     ",
                end="\r",
            )
            request = {
                "custom_id": f"{record}",
                "method": "POST",
                "url": "/v1/chat/completions",
                "body": {
                    "model": model,
                    "messages": [
                        {
                            "role": "developer",
                            "content": f'You will be given a list of jewish names with one name on each line of the input. For each name you must determine if it refers to the same person as the target name "{df.iloc[record]["title"]}". The names have been transliterated from the hebrew alphabet and may be different from the target name even if the names refer to the same person. For each name, replace it with "True" or "False" depending on whether or not the names refer to the same person. You must provide an answer for all {len(blocks[record])} names.',
                        },
                        {
                            "role": "user",
                            "content": create_name_list(blocks[record], blocks_df),
                        },
                    ],
                    "max_tokens": max_tokens_per_request,
                },
            }
            request_string = json.dumps(request)
            file.write(request_string + "\n")
        update_history(f"New batch file written at {filepath}")
        print("\n")
        print("Writing complete.")


def upload_batch_file(filepath):
    print(
        f'Are you sure you want to upload the file {filepath}?\nType "upload" to upload the file:'
    )
    if input() == "upload":
        print("Uploading...")
        batch_file = client.files.create(file=open(filepath, "rb"), purpose="batch")
        print(f"Uploading successful. Object returned:\n{batch_file}")
        update_history(f"\nBatch file at {filepath} uploaded:\n{batch_file}")


def create_batch_job(file_object_id):
    print("Creating batch job...")
    batch_job = client.batches.create(
        input_file_id=file_object_id,
        endpoint="/v1/chat/completions",
        completion_window="24h",
    )
    print(f"Batch job created. Object returned:\n{batch_job}")
    update_history(f"\nBatch job for file ID {file_object_id} created:\n{batch_job}")


def check_batch_status(batch_job_id):
    print("Retrieving batch job...")
    batch_job = client.batches.retrieve(batch_job_id)
    print(f"Retrieval successful. Status is {batch_job.status}.")
    update_history(
        f"\nBatch job with ID {batch_job_id} checked. Status was {batch_job.status}:\n{batch_job}"
    )


def retrieve_file_content(file_object_id):
    print("Retrieving file contents...")
    content = client.files.content(file_object_id).content
    print("Enter filepath to save at:")
    filepath = input()
    with open(filepath, "wb") as file:
        file.write(content)
    update_history(
        f"\nSaving of file with ID {file_object_id} completed.\nContents saved to: {filepath}"
    )


def list_uploaded_files():
    print("Retrieving files...")
    files = client.files.list()
    print("Found the following files:")
    for file in files:
        print(
            f"ID: {file.id} \tFilename: {file.filename} \tCreated at: {datetime.fromtimestamp(file.created_at)} \tPurpose: {file.purpose}"
        )


def delete_file(file_object_id):
    print(
        'Are you sure you want to delete this file?\nType "delete" to delete the file:'
    )
    if input() == "delete":
        response = client.files.delete(file_object_id)
        if response.deleted:
            print("File deleted successfully.")
            update_history(f"\nDeletion of file with ID {file_object_id} succeeded.")
        else:
            print("File could not be deleted.")
            update_history(f"\nDeletion of file with ID {file_object_id} failed.")


def list_batch_jobs():
    print("Retrieving batch jobs...")
    jobs = client.batches.list()
    print("Found the following batch jobs:")
    for job in jobs:
        print(
            f"ID: {job.id} \tInput file: {job.input_file_id} \t Output file: {job.output_file_id}\tCreated at: {datetime.fromtimestamp(job.created_at)} \tStatus: {job.status}"
        )


def cancel_batch_job(batch_job_id):
    print(
        'Are you sure you want to cancel this batch job?\nType "cancel" to cancel the job:'
    )
    if input() == "cancel":
        print("Cancelling batch job...")
        try:
            job = client.batches.cancel(batch_job_id)
            print(f"Job status is {job.status}.")
            update_history(f"\nBatch job with ID {batch_job_id} cancelled.")
        except openai.ConflictError:
            print("Job could not be cancelled.")
            update_history(
                f"\nBatch job with ID {batch_job_id} could not be cancelled."
            )


if __name__ == "__main__":
    df = pd.read_csv(
        r"datasets\testset15-Zylbercweig-Laski\LASKI.tsv", sep="\t", header=0
    )
    blocks_df = pd.read_csv(
        r"datasets\testset15-Zylbercweig-Laski\Zylbercweig_roman.csv",
        sep="\t",
        header=0,
    )
    blocks = {}
    with open(r"app\blocks.json") as file:
        print("Retrieving blocks...")
        blocks = json.load(file)
        # NOTE outside of textFiltering, blocks are lists, not sets!
        blocks = {int(k): list(v) for k, v in blocks.items()}

    # setup the client as a global variable
    with open("secrets.json", "r") as file:
        secrets = json.load(file)
        global client
        client = openai.OpenAI(
            organization=secrets["organization"],
            project=secrets["project"],
            api_key=secrets["api_key"],
        )

    choice = ""
    while choice != "exit":
        print(
            'Type "exit" to quit.\nType "write" to create a new batch file.\nType "upload" to upload a batch file (.jsonl).\nType "create" to create a new batch job with an uploaded file.\nType "check" for detailed information on an existing batch job.\nType "save" to save the contents of a file locally.\nType "files" to view all available files.\nType "delete" to delete a file.\nType "jobs" to view all batch jobs.\nType "cancel" to cancel a batch job in progress.'
        )
        choice = input()
        match choice:
            case "write":
                print("WRITE selected.")
                print("Enter filename for new .jsonl file:")
                filename = input()
                prepare_batch_file(blocks, df, blocks_df, "app/" + filename + ".jsonl")

            case "upload":
                print("UPLOAD selected.")
                print("Enter path of .jsonl file:")
                try:
                    filepath = input()
                    if filepath.endswith(".jsonl"):
                        upload_batch_file(filepath)
                    else:
                        print("Only .jsonl files allowed!")
                except OSError:
                    print(f"File not found at {filepath}")

            case "create":
                print("CREATE selected.")
                print("Enter ID of batch file (Check history for uploads):")
                file_object_id = input()
                create_batch_job(file_object_id)

            case "check":
                print("CHECK selected.")
                print("Enter ID of batch job:")
                batch_job_id = input()
                check_batch_status(batch_job_id)

            case "save":
                print("SAVE selected.")
                print("Enter ID of file to save:")
                file_object_id = input()
                retrieve_file_content(file_object_id)

            case "files":
                print("FILES selected.")
                list_uploaded_files()

            case "delete":
                print("DELETE selected.")

                print("Enter ID of file to delete:")
                file_object_id = input()
                delete_file(file_object_id)

            case "jobs":
                print("JOBS selected.")
                list_batch_jobs()

            case "cancel":
                print("CANCEL selected.")
                print("Enter ID of batch job:")
                batch_job_id = input()
                cancel_batch_job(batch_job_id)
