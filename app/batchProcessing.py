import time
from openai import OpenAI
import json
import pandas as pd
import datetime

# template
# {"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-3.5-turbo-0125", "messages": [{"role": "system", "content": "You are a helpful assistant."},{"role": "user", "content": "Hello world!"}],"max_tokens": 1000}}


def update_history(string):
    with open(r"app\openAiBatchHistory.txt", "a") as history:
        history.write(f"{datetime.datetime.now()}\t\t" + string + "\n\n")


def create_name_list(block, blocks_df):
    # given a set of record indexes, fetch each name from their dataframe and write a string where each name is on a new line
    name_list = ""
    for index in block:
        name_list += blocks_df.iloc[index]["title"] + "\n"
    name_list = name_list[:-1]
    return name_list


def prepare_batch_file(
    blocks,
    df,
    blocks_df,
    filepath,
    model="gpt-4.1-nano",
    max_tokens_per_request=5000,
):
    # given a blocks-dictionary as generated by textBlocking.py, the dataset the blocks were made for "df",
    # and the dataset used to create those blocks "blocks_df", write a file with gpt-4.1-nano requests for batch processing
    print(f"Overwriting {filepath}")

    for i in range(10):
        print(f"You have {10-i} seconds to cancel! ", end="\r")
        time.sleep(1)

    with open(filepath, "w", encoding="utf-8") as file:
        for record in blocks:
            print(
                f"Writing request for block {record}     ",
                end="\r",
            )
            request = {
                "custom_id": f"{record}",
                "method": "POST",
                "url": "/v1/chat/completions",
                "body": {
                    "model": model,
                    "messages": [
                        {
                            "role": "developer",
                            "content": f'You will be given a list of jewish names with one name on each line of the input. For each name you must determine if it refers to the same person as the target name "{df.iloc[record]["title"]}". The names have been transliterated from the hebrew alphabet and may be different from the target name even if the names refer to the same person. For each name, replace it with "True" or "False" depending on whether or not the names refer to the same person. You must provide an answer for all {len(blocks[record])} names.',
                        },
                        {
                            "role": "user",
                            "content": create_name_list(blocks[record], blocks_df),
                        },
                    ],
                    "max_tokens": max_tokens_per_request,
                },
            }
            request_string = json.dumps(request)
            file.write(request_string + "\n")
        update_history(f"New batch file written at {filepath}")
        print("\n")
        print("Writing complete.")


def upload_batch_file(filepath):
    print(
        f'Are you sure you want to upload the file {filepath}?\nType "upload" to upload the file.'
    )
    if input() == "upload":
        print("Uploading...")
        batch_file = client.files.create(file=open(filepath, "rb"), purpose="batch")
        print(f"Uploading successful. Object returned:\n{batch_file}")
        update_history(f"\nBatch file at {filepath} uploaded:\n{batch_file}")


def create_batch_job(file_object_id):
    print("Creating batch job...")
    batch_job = client.batches.create(
        input_file_id=file_object_id,
        endpoint="/v1/chat/completions",
        completion_window="24h",
    )
    print(f"Batch job created. Object returned:\n{batch_job}")
    update_history(f"\nBatch job for file ID {file_object_id} created:\n{batch_job}")


def check_batch_status(batch_job_id):
    print("Retrieving batch job...")
    batch_job = client.batches.retrieve(batch_job_id)
    print(f"Retrieval successful. Status is {batch_job.status}.")
    update_history(
        f"\nBatch job with ID {batch_job_id} checked. Status was {batch_job.status}:\n{batch_job}"
    )


def retrieve_batch_results(batch_job_id, filepath):
    print("Retrieving results...")
    batch_job = client.batches.retrieve(batch_job_id)
    result_file_id = batch_job.output_file_id
    if result_file_id == None:
        print(f"Batch job is not complete. Status is {batch_job.status}")
        update_history(
            f"\nSaving of result of job with ID {batch_job_id} attempted. Status was {batch_job.status}:\n{batch_job}"
        )
        return
    result = client.files.content(result_file_id).content
    print("Enter filepath of output file:")
    filepath = input()
    with open(filepath, "wb") as file:
        file.write(result)
    update_history(
        f"\nSaving of result of job with ID {batch_job_id} completed.\nContent of result file with ID {result_file_id} saved to: {filepath}"
    )


if __name__ == "__main__":
    df = pd.read_csv(
        r"datasets\testset15-Zylbercweig-Laski\LASKI.tsv", sep="\t", header=0
    )
    blocks_df = pd.read_csv(
        r"datasets\testset15-Zylbercweig-Laski\Zylbercweig_roman.csv",
        sep="\t",
        header=0,
    )
    blocks = {}
    with open(r"app\blocks.json") as file:
        print("Retrieving blocks...")
        blocks = json.load(file)
        blocks = {int(k): set(v) for k, v in blocks.items()}

    # setup the client as a global variable
    with open("secrets.json", "r") as file:
        secrets = json.load(file)
        global client
        client = OpenAI(
            organization=secrets["organization"],
            project=secrets["project"],
            api_key=secrets["api_key"],
        )

    choice = ""
    while choice != "exit":
        print(
            'Type "exit" to quit.\nType "write" to create a new batch file.\nType "upload" to upload a batch file (.jsonl).\nType "create" to create a new batch job with an uploaded file.\nType "check" to check the status of an existing batch job.\nType "save" to save the results of a completed batch job locally.'
        )
        choice = input()
        match choice:
            case "write":
                print("WRITE selected.")
                print("Enter filename for new .jsonl file:")
                filename = input()
                prepare_batch_file(blocks, df, blocks_df, "app/" + filename + ".jsonl")

            case "upload":
                print("UPLOAD selected.")
                print("Enter path of .jsonl file:")
                try:
                    filepath = input()
                    if filepath.endswith(".jsonl"):
                        upload_batch_file(filepath)
                    else:
                        print("Only .jsonl files allowed!")
                except OSError:
                    print(f"File not found at {filepath}")

            case "create":
                print("CREATE selected.")
                print("Enter ID of batch file (Check history for uploads):")
                file_object_id = input()
                create_batch_job(file_object_id)

            case "check":
                print("CHECK selected.")
                print("Enter ID of batch job:")
                batch_job_id = input()
                check_batch_status(batch_job_id)

            case "save":
                print("SAVE selected.")
                print("Enter ID of batch job:")
                batch_job_id = input()
                retrieve_batch_results(batch_job_id)
